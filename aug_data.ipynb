{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbz9jwtdrK5ueLA4bKbMk5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wanla9999/guest/blob/master/aug_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdZak75fywen",
        "outputId": "da0efec7-f6d3-4575-a9b2-ebdddbd39cf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tmp/ipython-input-1-1142894976.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU是否可用： True\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU是否可用：\",tf.test.is_gpu_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\"\"\"#cic_2017\n",
        "label_name = \"label\"\n",
        "extra_label_name1 = ' Label'\n",
        "extra_label_name2 = 'old_label'\n",
        "path = \"/content/Augmented_CIC-IDS2017.csv\"\n",
        "df = pd.read_csv(path)\n",
        "#df = dd.read_csv(path)\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "# X will contain all features except the label columns\n",
        "X = df.drop(['label',' Label','old_label','label_encoded'], axis=1)\n",
        "print(X.head())\n",
        "# Y will be the encoded labels\n",
        "y = df['label_encoded']\n",
        "print(y.head())\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\"\"\"\n"
      ],
      "metadata": {
        "id": "2kS4Cz_zzIeF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "51234fc7-504b-4384-843f-157ec5becf62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#cic_2017\\nlabel_name = \"label\"\\nextra_label_name1 = \\' Label\\'\\nextra_label_name2 = \\'old_label\\'\\npath = \"/content/Augmented_CIC-IDS2017.csv\"\\ndf = pd.read_csv(path)\\n#df = dd.read_csv(path)\\nlabel_encoder = LabelEncoder()\\ndf[\"label_encoded\"] = label_encoder.fit_transform(df[\"label\"])\\n# X will contain all features except the label columns\\nX = df.drop([\\'label\\',\\' Label\\',\\'old_label\\',\\'label_encoded\\'], axis=1)\\nprint(X.head())\\n# Y will be the encoded labels\\ny = df[\\'label_encoded\\']\\nprint(y.head())\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(path,label_name,extra_label_name1,extra_label_name2):\n",
        "    df = pd.read_csv(path)\n",
        "    #df = df.dropna(axis=0,how='any')# 删除全为 NaN 的行\n",
        "    #df = dd.read_csv(path)\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[\"label_encoded\"] = label_encoder.fit_transform(df[label_name])\n",
        "    # X will contain all features except the label columns\n",
        "    if label_name == 'attack_cat':\n",
        "        X = df.drop([label_name,'label_encoded'], axis=1)\n",
        "    elif label_name == 'label':\n",
        "        X = df.drop([label_name,extra_label_name1,extra_label_name2,'label_encoded'], axis=1)\n",
        "\n",
        "    # Identify categorical columns\n",
        "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Apply one-hot encoding to categorical columns\n",
        "    X = pd.get_dummies(X, columns=categorical_cols, dummy_na=False)\n",
        "\n",
        "    print(X.head())\n",
        "    # Y will be the encoded labels\n",
        "    y = df['label_encoded']\n",
        "    print(y.head())\n",
        "    #X, y = make_classification(n_samples=5000, n_features=50, random_state=42)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "#cic_2017\n",
        "#label_name = \"label\"\n",
        "#extra_label_name1 = ' Label'\n",
        "#extra_label_name2 = 'old_label'\n",
        "#path = \"/content/Augmented_CIC-IDS2017.csv\"\n",
        "#unsw_nb15\n",
        "label_name = \"attack_cat\"\n",
        "extra_label_name1 = ''\n",
        "extra_label_name2 = ''\n",
        "path = \"/content/Augmented-UNSW_NB15.csv\"\n",
        "X_train, X_test, y_train, y_test = process_data(path, label_name, extra_label_name1, extra_label_name2)\n",
        "#numpy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOs5pC5y0o2a",
        "outputId": "e89bcd11-381f-4e6a-f778-23aefdf415f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id       dur  spkts  dpkts  sbytes  dbytes       rate  sttl  dttl  \\\n",
            "0   1  0.121478      6      4     258     172  74.087490   252   254   \n",
            "1   2  0.649902     14     38     734   42014  78.473372    62   252   \n",
            "2   3  1.623129      8     16     364   13186  14.170161    62   252   \n",
            "3   4  1.681642     12     12     628     770  13.677108    62   252   \n",
            "4   5  0.449454     10      6     534     268  33.373826   254   252   \n",
            "\n",
            "          sload  ...  state_CLO  state_CON  state_ECO  state_FIN  state_INT  \\\n",
            "0  14158.942380  ...      False      False      False       True      False   \n",
            "1   8395.112305  ...      False      False      False       True      False   \n",
            "2   1572.271851  ...      False      False      False       True      False   \n",
            "3   2740.178955  ...      False      False      False       True      False   \n",
            "4   8561.499023  ...      False      False      False       True      False   \n",
            "\n",
            "   state_PAR  state_REQ  state_RST  state_URN  state_no  \n",
            "0      False      False      False      False     False  \n",
            "1      False      False      False      False     False  \n",
            "2      False      False      False      False     False  \n",
            "3      False      False      False      False     False  \n",
            "4      False      False      False      False     False  \n",
            "\n",
            "[5 rows x 197 columns]\n",
            "0    3\n",
            "1    3\n",
            "2    3\n",
            "3    3\n",
            "4    3\n",
            "Name: label_encoded, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K近邻\n",
        "model1 = KNeighborsClassifier(\n",
        "    n_neighbors=10,\n",
        "    n_jobs=-1,  # 使用所有CPU核心\n",
        "    leaf_size=30  # 调整树的大小影响并行效率\n",
        ")\n",
        "# 决策树\n",
        "model2 = DecisionTreeClassifier(random_state=77)\n",
        "# 随机森林\n",
        "model3 = RandomForestClassifier(\n",
        "    n_estimators=1000,\n",
        "    max_features='sqrt',\n",
        "    max_depth=15,\n",
        "    min_samples_leaf=3,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "# 神经网络\n",
        "model4 = MLPClassifier(hidden_layer_sizes=(16, 8), random_state=77, max_iter=10000)\n",
        "\n",
        "model_list = [model1, model2, model3, model4]\n",
        "model_name = ['K近邻', '决策树', '随机森林', '神经网络']\n",
        "\n",
        "\n",
        "def evaluation(y_test, y_predict):\n",
        "    print(\"------evaluation------\")\n",
        "    accuracy = classification_report(y_test, y_predict, output_dict=True)['accuracy']\n",
        "    s = classification_report(y_test, y_predict, output_dict=True)['weighted avg']\n",
        "    precision = s['precision']\n",
        "    recall = s['recall']\n",
        "    f1_score = s['f1-score']\n",
        "    # kappa=cohen_kappa_score(y_test, y_predict)\n",
        "    return accuracy, precision, recall, f1_score  # , kappa\n",
        "\n",
        "\n",
        "df_eval=pd.DataFrame(columns=['Accuracy','Precision','Recall','F1_score'])\n",
        "for i in range(4):\n",
        "  print(i)\n",
        "  model_C=model_list[i]\n",
        "  name=model_name[i]\n",
        "  model_C.fit(X_train, y_train)\n",
        "  print(\"----fit done-----\")\n",
        "  pred=model_C.predict(X_test)\n",
        "  #s=classification_report(y_test, pred)\n",
        "  s=evaluation(y_test,pred)\n",
        "  df_eval.loc[name,:]=list(s)\n",
        "  #path = 'DataSets/output.csv'\n",
        "  #df_eval.to_csv(path, index=True)\n",
        "print(df_eval.head())"
      ],
      "metadata": {
        "id": "4dSmshdU02as",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a688d231-dcae-41c3-b6f3-c020145c8cec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "----fit done-----\n",
            "------evaluation------\n",
            "1\n",
            "----fit done-----\n",
            "------evaluation------\n",
            "2\n",
            "----fit done-----\n",
            "------evaluation------\n",
            "3\n",
            "----fit done-----\n",
            "------evaluation------\n",
            "      Accuracy Precision    Recall  F1_score\n",
            "K近邻   0.724432   0.73476  0.724432  0.710645\n",
            "决策树   0.871776  0.873765  0.871776  0.872734\n",
            "随机森林  0.863683  0.877269  0.863683  0.836781\n",
            "神经网络  0.470514   0.26169  0.470514  0.301309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vD23KSCG9rpp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}